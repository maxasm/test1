Gap analysis (excluding Docker/Portainer/deployment)
Below are the items from the gig spec that are not implemented yet (or are only partially implemented) in this repo as it exists right now.

1) “Vanna AI 2.0 (latest) strictly following official docs”
Not implemented (core gap): main.py does not actually use Vanna for NL→SQL.
Evidence: There is no import vanna usage and no Vanna() agent initialization anywhere in main.py. Instead, VannaService directly calls OpenAI().chat.completions.create() and hand-builds a prompt.
Implication: You are not following Vanna’s official patterns/tools (RunSqlTool, VisualizeDataTool, etc.), and you won’t benefit from Vanna’s agent framework.
2) “Conversation context via Vanna placeholder/auth approach”
Partially implemented: API accepts user and conversation_id and uses them to filter Chroma queries.
Not implemented (per spec):
No integration with Vanna placeholder/auth flow (the placeholder/auth approach referenced in the requirements).
No actual “conversation context” beyond “memory filtering”. There is no chat history, message state, or tool-state per conversation being passed through an agent framework.
3) “Agent Memory via ChromaAgentMemory (ChromaDB)”
Not implemented (core gap): You are using ChromaDB directly as a custom vector store (ChromaMemoryManager), not ChromaAgentMemory.
Evidence: No import or usage of ChromaAgentMemory anywhere.
Partially meets intent: It does persist “question → SQL” pairs in Chroma, but that’s not the same thing as Vanna’s agent memory integration and “save successful tool usage patterns”.
4) “Must save successful tool usage patterns to memory”
Not implemented:
Current memory stores only:
question
sql_query
metadata (user, conversation_id, timestamp, confidence)
There is no tool framework in use, so there are no “tool usage patterns” being recorded (e.g., tool name, tool inputs/outputs, success/failure, latency, error types).
5) “Golden query storage” + “reuse for similar future queries”
Partially implemented:
The app saves queries after successful execution (save_memory() is called after execute_query()).
Similarity search is used as a cache with a distance threshold.
Not fully implemented (as described):
No explicit “golden query” concept/flagging, review workflow, or separation between:
“auto-saved”
“human-approved golden”
No embedding of (question + sql + schema + tool trace); it embeds only the question text.
No robust notion of “successful executions” beyond “didn’t throw pymysql.Error” (e.g., correctness signals, row counts, user feedback).
6) “FastAPI clean REST structure + proper logging”
Mostly implemented:
FastAPI exists, POST /api/chat, GET /health, plus GET /api/memory/{user}/{conversation_id}.
Structured logging via structlog.
Missing / weak spots:
No request correlation id / trace id (helpful for debugging per conversation).
No endpoint for inspecting “active tools and tool usage” (because tools aren’t implemented).
7) “Expose Vanna agent that can query MySQL (RunSqlTool + VisualizeDataTool + ChartComponent)”
Not implemented (core gap):
There is no Vanna agent, and no Vanna tools wired.
The current “chart” output is a custom Plotly config generator, not Vanna’s VisualizeDataTool + ChartComponent pipeline.
8) “OpenAI configuration via env vars with defaults like gpt-5”
Partially implemented:
Uses os.getenv("OPENAI_API_KEY") and os.getenv("OPENAI_MODEL", "gpt-4").
Mismatch vs requirement:
Requirement suggests default fallback like "gpt-5"; your fallback is "gpt-4".
Also .env currently contains what looks like a real key value in OPENAI_API_PROJECT_KEY (this is a security issue, but you didn’t ask me to fix it).
9) “Observability / WebUI proposal to inspect memory/tools/context”
Not implemented:
There is no WebUI.
There’s only a raw JSON memory listing endpoint.
Since tools are not implemented, there’s nothing to inspect regarding tool usage.